{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 02:16:01.829000: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 02:16:01.829059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 02:16:01.829926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 02:16:01.834683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 02:16:02.395612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ali/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATRURES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/train_clean.txt'\n",
    "val_dir = 'Dataset/val_clean.txt'\n",
    "test_dir = 'Dataset/test_clean.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_dir, 'r', encoding='utf8') as f:\n",
    "    train = f.read()\n",
    "with open(val_dir, 'r', encoding='utf8') as f:\n",
    "    val = f.read()\n",
    "with open(test_dir, 'r', encoding='utf8') as f:\n",
    "    test = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dir = 'pkl_dir/X_train.txt'\n",
    "y_train_dir = 'pkl_dir/y_train.txt'\n",
    "X_val_dir = 'pkl_dir/X_val.txt'\n",
    "y_val_dir = 'pkl_dir/y_val.txt'\n",
    "X_test_dir = 'pkl_dir/X_test.txt'\n",
    "y_test_dir = 'pkl_dir/y_test.txt'\n",
    "\n",
    "if EXTRACT_FEATRURES:\n",
    "    X_train, y_train = extract_features(train, max_len)\n",
    "    X_val, y_val = extract_features(val, max_len)\n",
    "    X_test, y_test = extract_features(test, max_len)\n",
    "\n",
    "    with open(X_train_dir, 'wb') as f:\n",
    "        pickle.dump(X_train, f)\n",
    "    with open(y_train_dir, 'wb') as f:\n",
    "        pickle.dump(y_train, f)\n",
    "    with open(X_val_dir, 'wb') as f:\n",
    "        pickle.dump(X_val, f)\n",
    "    with open(y_val_dir, 'wb') as f:\n",
    "        pickle.dump(y_val, f)\n",
    "    with open(X_test_dir, 'wb') as f:\n",
    "        pickle.dump(X_test, f)\n",
    "    with open(y_test_dir, 'wb') as f:\n",
    "        pickle.dump(y_test, f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_dir, 'rb') as f:\n",
    "        X_train = pickle.load(f)\n",
    "    with open(y_train_dir, 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open(X_val_dir, 'rb') as f:\n",
    "        X_val = pickle.load(f)\n",
    "    with open(y_val_dir, 'rb') as f:\n",
    "        y_val = pickle.load(f)\n",
    "    with open(X_test_dir, 'rb') as f:\n",
    "        X_test = pickle.load(f)\n",
    "    with open(y_test_dir, 'rb') as f:\n",
    "        y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0001( قَوْلُهُ لِعَدَمِ مَا تَتَعَلَّقُ إلَخْ ) أَيْ الْوَصِيَّةُ ( قَوْلُهُ مَا مَرَّ"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "i = 7\n",
    "for i in range(50):\n",
    "    print(chr(X_train[j][i]), end='')\n",
    "    print(id2diacritic[y_train[j][i]], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 5000\n",
    "np.random.seed(42)\n",
    "indices = np.arange(test_len)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "y_test = y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentence_encoder = LabelEncoder().fit(X_train.flatten())\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_1000.pkl', 'rb'))          # conv_1000\n",
    "X_train = sentence_encoder.transform(X_train.flatten()).reshape(X_train.shape).astype(np.int16)\n",
    "X_val = sentence_encoder.transform(X_val.flatten()).reshape(X_val.shape).astype(np.int16)\n",
    "X_test = sentence_encoder.transform(X_test.flatten()).reshape(X_test.shape).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_eval(x_np, y_np):\n",
    "    X_tensor = torch.tensor(x_np, dtype=torch.int32)\n",
    "    y_tensor = torch.tensor(y_np, dtype=torch.int32)\n",
    "    model.eval()\n",
    "    predictions = torch.zeros_like(y_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            inputs = X_tensor[i:i+batch_size].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions[i:i+batch_size] = torch.max(outputs.data, 2)\n",
    "            del inputs, outputs\n",
    "\n",
    "    return predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DER(X, y):\n",
    "    predictions = batch_eval(X, y)\n",
    "    ignore = {PAD, SOS, EOS, '!', '«', ']', '[', '}', ':', '\"', '-', '»', '؛', ')', '،', '؟', '(', '{', '/', ' '}\n",
    "    cnt = 0\n",
    "    for itm in ignore:\n",
    "        cnt += np.sum(X == sentence_encoder.transform(np.array([ord(itm)]))[0])\n",
    "    accuracy = (np.sum(predictions == y) - cnt) / (predictions.shape[0] * predictions.shape[1] - cnt)\n",
    "    acc_t = np.sum(predictions == y) / (predictions.shape[0] * predictions.shape[1])\n",
    "    return 1 - accuracy, acc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, X_val))\n",
    "y_train = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Optional\n",
    "\n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NewModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=56, embedding_dim=25)\n",
    "\n",
    "        # Add Conv1d layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=25, out_channels=256, kernel_size=11, padding=5)\n",
    "        self.bn_conv1 = nn.BatchNorm1d(max_len)\n",
    "        self.dropout_conv1 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=256, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "        self.bn1 = nn.BatchNorm1d(max_len)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=5, padding=2)\n",
    "        self.bn_conv2 = nn.BatchNorm1d(max_len)\n",
    "        self.dropout_conv2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.lstm2 = nn.LSTM(input_size=512, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "        self.bn2 = nn.BatchNorm1d(max_len)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.bn_conv3 = nn.BatchNorm1d(max_len)\n",
    "        self.dropout_conv3 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.dense1 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.bn3 = nn.BatchNorm1d(max_len)\n",
    "\n",
    "        self.dense2 = nn.Linear(in_features=512, out_features=512)\n",
    "        self.bn4 = nn.BatchNorm1d(max_len)\n",
    "        \n",
    "        self.dense3 = nn.Linear(in_features=512, out_features=15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Apply Conv1d layer\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, channels, seq_len)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = x.permute(0, 2, 1)  # Change back to (batch_size, seq_len, channels)\n",
    "        x = self.bn_conv1(x)\n",
    "        x = self.dropout_conv1(x)\n",
    "\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, channels, seq_len)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.bn_conv2(x)\n",
    "        x = self.dropout_conv2(x)\n",
    "\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # Change to (batch_size, channels, seq_len)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.bn_conv3(x)\n",
    "        x = self.dropout_conv3(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.dense1(x)))\n",
    "        x = F.relu(self.bn4(self.dense2(x)))\n",
    "\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NewModel().to(device)\n",
    "model = torch.load('model_conv_1000.ckpt', map_location=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0004\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, eps=1e-7)\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torch.nn.functional as F\n",
    "# from typing import List, Optional\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Model, self).__init__()\n",
    "#         self.embedding = nn.Embedding(num_embeddings=np.unique(X_train).shape[0], embedding_dim=25)\n",
    "\n",
    "#         self.prenet = nn.Linear(in_features=25, out_features=256)\n",
    "#         self.bnpre = nn.BatchNorm1d(max_len)\n",
    "#         self.dropoutpre = nn.Dropout(p=0.5)\n",
    "\n",
    "#         self.lstm1 = nn.GRU(input_size=256, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "#         self.bn1 = nn.BatchNorm1d(max_len)\n",
    "#         self.dropout1 = nn.Dropout(p=0.5)\n",
    "        \n",
    "#         self.lstm2 = nn.GRU(input_size=512, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "#         self.bn2 = nn.BatchNorm1d(max_len)\n",
    "#         self.dropout2 = nn.Dropout(p=0.5)\n",
    "\n",
    "#         self.lstm3 = nn.GRU(input_size=512, hidden_size=256, batch_first=True, bidirectional=True)\n",
    "#         self.bn3 = nn.BatchNorm1d(max_len)\n",
    "#         self.dropout3 = nn.Dropout(p=0.5)\n",
    "\n",
    "#         self.dense1 = nn.Linear(in_features=512, out_features=512)\n",
    "#         self.bnd1 = nn.BatchNorm1d(max_len)\n",
    "\n",
    "#         self.dense2 = nn.Linear(in_features=512, out_features=512)\n",
    "#         self.bnd2 = nn.BatchNorm1d(max_len)\n",
    "        \n",
    "#         self.dense3 = nn.Linear(in_features=512, out_features=np.unique(y_train).shape[0])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.embedding(x)\n",
    "\n",
    "#         x = self.prenet(x)\n",
    "#         x = self.bnpre(x)\n",
    "#         x = self.dropoutpre(x)\n",
    "\n",
    "\n",
    "#         x, _ = self.lstm1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.dropout1(x)\n",
    "\n",
    "#         x, _ = self.lstm2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.dropout2(x)\n",
    "\n",
    "#         x, _ = self.lstm3(x)\n",
    "#         x = self.bn3(x)\n",
    "#         x = self.dropout3(x)\n",
    "\n",
    "\n",
    "\n",
    "#         x = F.relu(self.bnd1(self.dense1(x)))\n",
    "#         x = F.relu(self.bnd2(self.dense2(x)))\n",
    "\n",
    "#         x = self.dense3(x)\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = Model().to(device)\n",
    "# model = torch.load('model_3gru.ckpt', map_location=device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# learning_rate = 0.0004\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, eps=1e-7)\n",
    "# print(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "batch_size = 120\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 20\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "\n",
    "#     X_train_tensor = torch.tensor(X_train, dtype=torch.int64).to(device)\n",
    "#     y_train_tensor = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
    "#     train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "#     accuracy = 0\n",
    "#     loss_cum_sum = 0\n",
    "#     len_ = 0\n",
    "#     for i, (x, y) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(x)\n",
    "#         loss = criterion(outputs.view(-1, np.unique(y_train).shape[0]), y.view(-1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         _, predicted = torch.max(outputs.data, 2)\n",
    "#         accuracy += (predicted == y).sum().item()\n",
    "#         loss_cum_sum += loss.item()\n",
    "#         len_ += y.size(0) * y.size(1)\n",
    "#         if (i + 1) % 1 == 0:\n",
    "#             print('Step [{}/{}], Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(i + 1, len(train_loader), epoch + 1, num_epochs, loss_cum_sum / (i + 1), accuracy / len_), end='\\r')\n",
    "#     print()\n",
    "#     del X_train_tensor, y_train_tensor, train_dataset, train_loader\n",
    "#     DER, acc_t = compute_DER(X_test, y_test)\n",
    "#     print('Test DER: {:.5f}, Test Accuracy: {:.4f}\\n'.format(DER, acc_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "# torch.save(model, 'model_3gru.ckpt')\n",
    "# torch.save(model, 'model_conv_m_newcleaner.ckpt')\n",
    "print(np.unique(y_train).shape[0])\n",
    "print(np.unique(X_train).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "17: 0, 2\n",
      "18: 6, 0\n",
      "19: 0, 12\n",
      "23: 2, 0\n",
      "24: 8, 4\n",
      "25: 6, 14\n",
      "26: 4, 0\n",
      "44: 2, 0\n",
      "46: 2, 6\n",
      "47: 0, 1\n",
      "54: 8, 4\n",
      "55: 6, 14\n",
      "59: 0, 2\n",
      "63: 14, 4\n",
      "72: 0, 6\n",
      "73: 6, 0\n",
      "79: 4, 0\n",
      "80: 4, 2\n",
      "89: 5, 0\n",
      "90: 4, 0\n",
      "100: 2, 0\n",
      "102: 0, 4\n",
      "104: 14, 1\n",
      "106: 4, 0\n",
      "112: 2, 0\n",
      "113: 14, 2\n",
      "117: 0, 6\n",
      "118: 6, 2\n",
      "119: 6, 0\n",
      "121: 0, 4\n",
      "123: 0, 1\n",
      "133: 2, 4\n",
      "137: 6, 4\n",
      "139: 14, 4\n",
      "140: 14, 2\n",
      "141: 2, 6\n",
      "143: 14, 6\n",
      "149: 14, 0\n",
      "154: 0, 4\n",
      "155: 0, 6\n",
      "157: 14, 10\n",
      "161: 14, 6\n",
      "162: 2, 0\n",
      "164: 14, 4\n",
      "165: 14, 10\n",
      "167: 0, 2\n",
      "168: 0, 8\n",
      "169: 0, 2\n",
      "181: 4, 2\n",
      "133 correct out of 182\n",
      "73.07692307692307 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:306: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "sentence_test_str = \"ليس للوكيل بالقبض أن يبرأ المدين أو يهب الدين له أو يأخذ رهنا من المدين في مقابل الدين أو يقبل إحالته على شخص آخر لكن له أن يأخذ كفيلا لكن ليس له أن يأخذ كفيلا بشرط براءة الأصيل انظر المادة ( 648 ) ( الأنقروي ، الطحطاوي وصرة الفتاوى ، البحر ) .\"\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_1000.pkl', 'rb'))         # 1000\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_1000.pkl', 'rb'))          # cbhg, 600\n",
    "# model = torch.load('model_conv_m.ckpt', map_location=device)\n",
    "\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_500.pkl', 'rb'))          # conv_m, 500\n",
    "sentence12, sentence22, label22, id22 = Test(sentence_test_str, model, sentence_encoder, max_len)\n",
    "golden_output = np.array([0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 2, 0, 12, 0, 14, 6, 0, 4, 14, 0, 0, 6, 0, 0, 0, 14, 14, 8, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 0, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2])\n",
    "\n",
    "x = np.array(label22[:len(golden_output)])\n",
    "for i in range(len(x)):\n",
    "    if (x[i] != golden_output[i]):\n",
    "        print(f'{i}: {x[i]}, {golden_output[i]}')\n",
    "    # print(f'{x[i]} {golden_output[i]}')\n",
    "print(f'{sum(x==golden_output)} correct out of {len(x)}')\n",
    "print(sum(x==golden_output)/len(x) * 100, \"%\")\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER: 0.02243741\n",
      "score: 0.97756259\n"
     ]
    }
   ],
   "source": [
    "DER, acc_t = compute_DER(X_test, y_test)\n",
    "print('DER: {:.8f}'.format(DER))\n",
    "print('score: {:.8f}'.format(1-DER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ayza tet7at fy trainer copy aw 7aga b3d kda 3lshan teshta8al\n",
    "# w yet7at m3aha function clean brdo xD\n",
    "\n",
    "def Test(test_sentences, model, sentence_encoder, max_len = 500):\n",
    "    # test_sentences: el text el kbeer bta3 el test (kaza gomla 3ady b dots b 3ak kteer kda)\n",
    "    # model: el model el hn-predict byh\n",
    "    # sentence_encoder: el encoder el hn-convert el text le numbers\n",
    "    test_sentences_clean = clean(test_sentences)\n",
    "    test_sentences_clean = test_sentences_clean.split('.')\n",
    "    # split on \\n as well, la mlhash lazma\n",
    "    \n",
    "    for test in test_sentences_clean:\n",
    "        if test == '':      # fy gomal fyha . w \\n, fa hyb2a fady, bnshelha\n",
    "            test_sentences_clean.remove(test)\n",
    "    # split 3la no2ta wa7da msh aktr, w \\n \n",
    "    # kda kda el clean bysheel el kaza no2ta\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    sentence1 = ''\n",
    "    sentence2 = ''\n",
    "    label2 = []\n",
    "    # arabic_letters = {'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س','ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي'}\n",
    "    \n",
    "    for sentence in test_sentences_clean:\n",
    "        sentence = SOS + sentence + EOS\n",
    "        for j in range(0, len(sentence), max_len//2):\n",
    "            current_sentence = sentence[j:j+max_len]\n",
    "            \n",
    "            current_sentence, labels = clamp_sentence(current_sentence, np.full((len(current_sentence)), diacritic2id[''], dtype = np.uint8), max_len)\n",
    "            test_sentence_clean = encode_sentence(current_sentence)\n",
    "            test_sentence_clean = sentence_encoder.transform(test_sentence_clean.reshape(-1)).reshape(1, -1)\n",
    "            \n",
    "            test_sentence_clean = torch.tensor(test_sentence_clean, dtype=torch.int32).to(device)\n",
    "            outputs = model(test_sentence_clean)\n",
    "            _, pred = torch.max(outputs.data, 2)\n",
    "            pred = pred.cpu().numpy().reshape(-1)\n",
    "\n",
    "            for i in range(len(current_sentence)):\n",
    "                sentence1 += current_sentence[i]\n",
    "                sentence1 += id2diacritic[pred[i]]\n",
    "            sentence1 += '\\n'\n",
    "\n",
    "            \n",
    "            if j == 0:\n",
    "                flag = np.array([ord('ء') <= ord(c) <= ord('ي') for c in current_sentence])\n",
    "\n",
    "                current_sentence = np.array(list(current_sentence))\n",
    "                pred = pred[flag]\n",
    "                \n",
    "            else:\n",
    "                flag = np.array([ord('ء') <= ord(c) <= ord('ي') for c in current_sentence[max_len//2:]])\n",
    "\n",
    "                current_sentence = np.array(list(current_sentence[max_len//2:]))\n",
    "                pred = pred[max_len//2:][flag]\n",
    "                \n",
    "            \n",
    "            current_sentence = current_sentence[flag]\n",
    "            sentence2 += ''.join(current_sentence)\n",
    "            label2 += list(pred)\n",
    "\n",
    "    id2 = np.arange(len(sentence2))\n",
    "            \n",
    "    return sentence1[1:-1], sentence2, label2, id2\n",
    "# model = torch.load('model_conv.ckpt', map_location=torch.device('cpu'))       # 3lshan t-load el model 3l cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "17: 0, 2\n",
      "18: 6, 0\n",
      "19: 0, 12\n",
      "179 correct out of 182\n",
      "98.35164835164835 %\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "sentence_test_str = \"ليس للوكيل بالقبض أن يبرأ المدين أو يهب الدين له أو يأخذ رهنا من المدين في مقابل الدين أو يقبل إحالته على شخص آخر لكن له أن يأخذ كفيلا لكن ليس له أن يأخذ كفيلا بشرط براءة الأصيل انظر المادة ( 648 ) ( الأنقروي ، الطحطاوي وصرة الفتاوى ، البحر ) .\"\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_1000.pkl', 'rb'))         # 1000\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_1000.pkl', 'rb'))          # cbhg, 600\n",
    "# model = torch.load('model_conv_m.ckpt', map_location=device)\n",
    "\n",
    "# sentence_encoder = pickle.load(open('sentence_encoders/sentence_encoder_500.pkl', 'rb'))          # conv_m, 500\n",
    "sentence12, sentence22, label22, id22 = Test(sentence_test_str, model, sentence_encoder, max_len)\n",
    "golden_output = np.array([0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 2, 0, 12, 0, 14, 6, 0, 4, 14, 0, 0, 6, 0, 0, 0, 14, 14, 8, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 0, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2])\n",
    "\n",
    "x = np.array(label22[:len(golden_output)])\n",
    "for i in range(len(x)):\n",
    "    if (x[i] != golden_output[i]):\n",
    "        print(f'{i}: {x[i]}, {golden_output[i]}')\n",
    "    # print(f'{x[i]} {golden_output[i]}')\n",
    "print(f'{sum(x==golden_output)} correct out of {len(x)}')\n",
    "print(sum(x==golden_output)/len(x) * 100, \"%\")\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER: 0.02243741\n",
      "score: 0.97756259\n"
     ]
    }
   ],
   "source": [
    "DER, acc_t = compute_DER(X_test, y_test)\n",
    "print('DER: {:.8f}'.format(DER))\n",
    "print('score: {:.8f}'.format(1-DER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2863922\n",
      "417359\n",
      "417359\n",
      "417359\n",
      "ليسللوكيلبالقبضأنيبرأالمدينأويهبالدينلهأويأخذرهنامنالمدينفيمقابلالدينأويقبلإحالتهعلىشخصآخرلكنلهأنيأخ\n"
     ]
    }
   ],
   "source": [
    "test_path = 'Testfrfr/test_no_diacritics.txt'\n",
    "with open(test_path, 'r', encoding='utf8') as f:\n",
    "    test = f.read()\n",
    "    \n",
    "sentence1, sentence2, label2, id2 = Test(test, model, sentence_encoder, max_len)\n",
    "print(len(sentence1))\n",
    "print(len(sentence2))\n",
    "print(len(label2))\n",
    "print(len(id2))\n",
    "print(sentence2[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 0, 6, 0, 0, 14, 6, 0, 4, 14, 0, 0, 6, 0, 0, 0, 14, 14, 8, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 0, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2]\n",
      "179 correct out of 182\n",
      "98.35164835164835 %\n"
     ]
    }
   ],
   "source": [
    "golden_output = np.array([0, 6, 0, 4, 6, 0, 4, 14, 4, 4, 14, 6, 0, 6, 4, 0, 6, 2, 0, 12, 0, 14, 6, 0, 4, 14, 0, 0, 6, 0, 0, 0, 14, 14, 8, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 6, 1, 14, 4, 6, 14, 6, 0, 4, 14, 4, 4, 14, 2, 0, 14, 4, 4, 14, 14, 8, 6, 4, 0, 6, 0, 6, 0, 0, 14, 0, 14, 0, 0, 2, 0, 0, 14, 0, 6, 5, 14, 0, 0, 0, 4, 6, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 0, 4, 6, 0, 6, 0, 0, 2, 0, 6, 0, 6, 2, 0, 0, 4, 14, 1, 14, 4, 0, 6, 4, 0, 0, 14, 0, 4, 14, 6, 0, 4, 14, 4, 2, 6, 2, 6, 14, 6, 0, 14, 8, 0, 14, 6, 0, 6, 4, 6, 4, 10, 14, 14, 8, 6, 0, 14, 4, 10, 0, 2, 8, 2, 14, 6, 0, 0, 14, 0, 14, 14, 6, 0, 6, 2])\n",
    "\n",
    "x = np.array(label2[:len(golden_output)])\n",
    "print(label2[:len(golden_output)])\n",
    "# for i in range(len(x)):\n",
    "#     print(f'{x[i]} {golden_output[i]}')\n",
    "print(f'{sum(x==golden_output)} correct out of {len(x)}')\n",
    "print(sum(x==golden_output)/len(x) * 100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle dump sentence2, label2, id2\n",
    "# pickle.dump(sentence2, open('sentence2.pkl', 'wb'))\n",
    "pickle.dump(label2, open('Answer2/label2.pkl', 'wb'))\n",
    "pickle.dump(id2, open('Answer2/id2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to Answer2/output.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "label2 = pickle.load(open('Answer2/label2.pkl', 'rb'))\n",
    "# print(type(label2[0]))\n",
    "# turn label 2 into a list instead of numpy array, using list comprehension\n",
    "\n",
    "label = [[ind, int(val)] for ind, val in enumerate(label2)]\n",
    "\n",
    "\n",
    "# Specify the file path\n",
    "csv_file_path = 'Answer2/output.csv'\n",
    "\n",
    "# Writing to CSV file\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['ID', 'label'])\n",
    "    csv_writer.writerows(label)\n",
    "\n",
    "print(f'Data has been written to {csv_file_path}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def diacritize_string(sentence_test_str, model, sentence_encoder, max_len):\n",
    "#     # sentence = SOS + sentence_test_str + EOS\n",
    "#     sentence = sentence_test_str\n",
    "#     sentence_no_diacritics, labels = extract_data_single(sentence)\n",
    "#     sentence_no_diac_clamped, labels_clamped = clamp_sentence(sentence_no_diacritics, labels, max_len)\n",
    "#     sentence, labels_encoded = encode_sentences(sentence_no_diac_clamped, labels_clamped)\n",
    "#     sentence = sentence_encoder.transform(sentence.reshape(-1)).reshape(1, -1)\n",
    "    \n",
    "#     sentence = torch.tensor(sentence, dtype=torch.int32).to(device)\n",
    "#     outputs = model(sentence)\n",
    "#     _, pred = torch.max(outputs.data, 2)\n",
    "#     pred = pred.cpu().numpy().reshape(-1)\n",
    "\n",
    "#     sentence = ''\n",
    "#     for i in range(len(sentence_no_diacritics)):\n",
    "#         sentence += sentence_no_diacritics[i]\n",
    "#         sentence += id2diacritic[pred[i]]\n",
    "            \n",
    "#     return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_test_str = '  أَلْفٌ فَقَالَ هِيَ مُضَارَبَةٌ لِفُلَانٍ بِالنِّصْفِ وَقَدْ رَبِحَ أَلْفًا فَقَالَ فُلَانٌ هِيَ بِضَاعَةٌ فَالْقَوْلُ قَوْلُ رَبِّ الْمَالِ'\n",
    "# print(sentence_test_str)\n",
    "# print(diacritize_string(SOS + sentence_test_str + EOS, model, sentence_encoder, max_len)[1:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
