{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACT_FEATRURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/train_clean.txt'\n",
    "val_dir = 'Dataset/val_clean.txt'\n",
    "test_dir = 'Dataset/test_clean.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_dir, 'r', encoding='utf8') as f:\n",
    "    train = f.read()\n",
    "with open(val_dir, 'r', encoding='utf8') as f:\n",
    "    val = f.read()\n",
    "with open(test_dir, 'r', encoding='utf8') as f:\n",
    "    test = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dir = 'pkl_dir/X_train.txt'\n",
    "y_train_dir = 'pkl_dir/y_train.txt'\n",
    "X_val_dir = 'pkl_dir/X_val.txt'\n",
    "y_val_dir = 'pkl_dir/y_val.txt'\n",
    "X_test_dir = 'pkl_dir/X_test.txt'\n",
    "y_test_dir = 'pkl_dir/y_test.txt'\n",
    "\n",
    "if EXTRACT_FEATRURES:\n",
    "    X_train, y_train = extract_features(train, max_len)\n",
    "    X_val, y_val = extract_features(val, max_len)\n",
    "    X_test, y_test = extract_features(test, max_len)\n",
    "\n",
    "    with open(X_train_dir, 'wb') as f:\n",
    "        pickle.dump(X_train, f)\n",
    "    with open(y_train_dir, 'wb') as f:\n",
    "        pickle.dump(y_train, f)\n",
    "    with open(X_val_dir, 'wb') as f:\n",
    "        pickle.dump(X_val, f)\n",
    "    with open(y_val_dir, 'wb') as f:\n",
    "        pickle.dump(y_val, f)\n",
    "    with open(X_test_dir, 'wb') as f:\n",
    "        pickle.dump(X_test, f)\n",
    "    with open(y_test_dir, 'wb') as f:\n",
    "        pickle.dump(y_test, f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_dir, 'rb') as f:\n",
    "        X_train = pickle.load(f)\n",
    "    with open(y_train_dir, 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open(X_val_dir, 'rb') as f:\n",
    "        X_val = pickle.load(f)\n",
    "    with open(y_val_dir, 'rb') as f:\n",
    "        y_val = pickle.load(f)\n",
    "    with open(X_test_dir, 'rb') as f:\n",
    "        X_test = pickle.load(f)\n",
    "    with open(y_test_dir, 'rb') as f:\n",
    "        y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "و\n",
      "َّ\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "i = 20\n",
    "print(chr(X_train[j][i]))\n",
    "print(id2diacritic[y_train[j][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 50000\n",
    "np.random.seed(42)\n",
    "indices = np.arange(test_len)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "y_test = y_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder = LabelEncoder().fit(X_train.flatten())\n",
    "X_train = sentence_encoder.transform(X_train.flatten()).reshape(X_train.shape).astype(np.int16)\n",
    "X_val = sentence_encoder.transform(X_val.flatten()).reshape(X_val.shape).astype(np.int16)\n",
    "X_test = sentence_encoder.transform(X_test.flatten()).reshape(X_test.shape).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class BatchNormConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A nn.Conv1d followed by an optional activation function, and nn.BatchNorm1d\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        kernel_size: int,\n",
    "        stride: int,\n",
    "        padding: int,\n",
    "        activation = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return self.bn(x)\n",
    "\n",
    "\n",
    "class Prenet(nn.Module):\n",
    "    \"\"\"\n",
    "    A prenet is a collection of linear layers with dropout(0.5),\n",
    "    and RELU activation function\n",
    "    Args:\n",
    "    config: the hyperparameters object\n",
    "    in_dim (int): the input dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_dim: int, prenet_depth: List[int] = [256, 128], dropout: int = 0.5\n",
    "    ):\n",
    "        \"\"\" Initializing the prenet module \"\"\"\n",
    "        super().__init__()\n",
    "        in_sizes = [in_dim] + prenet_depth[:-1]\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(in_size, out_size)\n",
    "                for (in_size, out_size) in zip(in_sizes, prenet_depth)\n",
    "            ]\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        \"\"\"Calculate forward propagation\n",
    "        Args:\n",
    "        inputs (batch_size, seqLen): the inputs to the prenet, the input shapes could\n",
    "        be different as it is being used in both encoder and decoder.\n",
    "        Returns:\n",
    "        Tensor: the output of  the forward propagation\n",
    "        \"\"\"\n",
    "        for linear in self.layers:\n",
    "            inputs = self.dropout(self.relu(linear(inputs)))\n",
    "        return inputs\n",
    "\n",
    "class Highway(nn.Module):\n",
    "    \"\"\"Highway Networks were developed by (Srivastava et al., 2015)\n",
    "    to overcome the difficulty of training deep neural networks\n",
    "    (https://arxiv.org/abs/1507.06228).\n",
    "    Args:\n",
    "    in_size (int): the input size\n",
    "    out_size (int): the output size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializing Highway networks\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.H = nn.Linear(in_size, out_size)\n",
    "        self.H.bias.data.zero_()\n",
    "        self.T = nn.Linear(in_size, out_size)\n",
    "        self.T.bias.data.fill_(-1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor):\n",
    "        \"\"\"Calculate forward propagation\n",
    "        Args:\n",
    "        inputs (Tensor):\n",
    "        \"\"\"\n",
    "        H = self.relu(self.H(inputs))\n",
    "        T = self.sigmoid(self.T(inputs))\n",
    "        return H * T + inputs * (1.0 - T)\n",
    "\n",
    "\n",
    "class CBHG(nn.Module):\n",
    "    \"\"\"The CBHG module (1-D Convolution Bank + Highway network + Bidirectional GRU)\n",
    "    was proposed by (Lee et al., 2017, https://www.aclweb.org/anthology/Q17-1026)\n",
    "    for a character-level NMT model.\n",
    "    It was adapted by (Wang et al., 2017) for building the Tacotron.\n",
    "    It is used in both the encoder and decoder  with different parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        out_dim: int,\n",
    "        K: int,\n",
    "        projections: List[int],\n",
    "        highway_layers: int = 4,\n",
    "    ):\n",
    "        \"\"\"Initializing the CBHG module\n",
    "        Args:\n",
    "        in_dim (int): the input size\n",
    "        out_dim (int): the output size\n",
    "        k (int): number of filters\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1d_banks = nn.ModuleList(\n",
    "            [\n",
    "                BatchNormConv1d(\n",
    "                    in_dim,\n",
    "                    in_dim,\n",
    "                    kernel_size=k,\n",
    "                    stride=1,\n",
    "                    padding=k // 2,\n",
    "                    activation=self.relu,\n",
    "                )\n",
    "                for k in range(1, K + 1)\n",
    "            ]\n",
    "        )\n",
    "        self.max_pool1d = nn.MaxPool1d(kernel_size=2, stride=1, padding=1)\n",
    "\n",
    "        in_sizes = [K * in_dim] + projections[:-1]\n",
    "        activations = [self.relu] * (len(projections) - 1) + [None]\n",
    "        self.conv1d_projections = nn.ModuleList(\n",
    "            [\n",
    "                BatchNormConv1d(\n",
    "                    in_size, out_size, kernel_size=3, stride=1, padding=1, activation=ac\n",
    "                )\n",
    "                for (in_size, out_size, ac) in zip(in_sizes, projections, activations)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.pre_highway = nn.Linear(projections[-1], in_dim, bias=False)\n",
    "        self.highways = nn.ModuleList([Highway(in_dim, in_dim) for _ in range(4)])\n",
    "\n",
    "        self.gru = nn.GRU(in_dim, out_dim, 1, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs, input_lengths=None):\n",
    "        # (B, T_in, in_dim)\n",
    "        x = inputs\n",
    "        x = x.transpose(1, 2)\n",
    "        T = x.size(-1)\n",
    "\n",
    "        # (B, in_dim*K, T_in)\n",
    "        # Concat conv1d bank outputs\n",
    "        x = torch.cat([conv1d(x)[:, :, :T] for conv1d in self.conv1d_banks], dim=1)\n",
    "        assert x.size(1) == self.in_dim * len(self.conv1d_banks)\n",
    "        x = self.max_pool1d(x)[:, :, :T]\n",
    "\n",
    "        for conv1d in self.conv1d_projections:\n",
    "            x = conv1d(x)\n",
    "\n",
    "        # (B, T_in, in_dim)\n",
    "        # Back to the original shape\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        if x.size(-1) != self.in_dim:\n",
    "            x = self.pre_highway(x)\n",
    "\n",
    "        # Residual connection\n",
    "        x += inputs\n",
    "        for highway in self.highways:\n",
    "            x = highway(x)\n",
    "\n",
    "        if input_lengths is not None:\n",
    "            x = nn.utils.rnn.pack_padded_sequence(x, input_lengths, batch_first=True)\n",
    "\n",
    "        # (B, T_in, in_dim*2)\n",
    "        self.gru.flatten_parameters()\n",
    "        outputs, _ = self.gru(x)\n",
    "\n",
    "        if input_lengths is not None:\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class CBHGModel(nn.Module):\n",
    "    \"\"\"CBHG model implementation as described in the paper:\n",
    "     https://ieeexplore.ieee.org/document/9274427\n",
    "\n",
    "    Args:\n",
    "    inp_vocab_size (int): the number of the input symbols\n",
    "    targ_vocab_size (int): the number of the target symbols (diacritics)\n",
    "    embedding_dim (int): the embedding  size\n",
    "    prenet_sizes (List[int]): the sizes of the prenet networks\n",
    "    cbhg_gru_units (int): the number of units of the CBHG GRU, which is the last\n",
    "    layer of the CBHG Model.\n",
    "    cbhg_filters (int): number of filters used in the CBHG module\n",
    "    cbhg_projections: projections used in the CBHG module\n",
    "\n",
    "    Returns:\n",
    "    diacritics Dict[str, Tensor]:\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_vocab_size: int,\n",
    "        targ_vocab_size: int,\n",
    "        embedding_dim: int = 512,\n",
    "        prenet_sizes: List[int] = [512, 256],\n",
    "        cbhg_gru_units: int = 256,\n",
    "        cbhg_filters: int = 16,\n",
    "        cbhg_projections: List[int] = [128, 256],\n",
    "        post_cbhg_layers_units: List[int] = [256, 256],\n",
    "        post_cbhg_use_batch_norm: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(inp_vocab_size, embedding_dim)\n",
    "\n",
    "        self.prenet = Prenet(embedding_dim, prenet_depth=prenet_sizes)\n",
    "\n",
    "        self.cbhg = CBHG(\n",
    "            prenet_sizes[-1],\n",
    "            cbhg_gru_units,\n",
    "            K=cbhg_filters,\n",
    "            projections=cbhg_projections,\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        post_cbhg_layers_units = [cbhg_gru_units] + post_cbhg_layers_units\n",
    "\n",
    "        for i in range(1, len(post_cbhg_layers_units)):\n",
    "            layers.append(\n",
    "                nn.LSTM(\n",
    "                    post_cbhg_layers_units[i - 1] * 2,\n",
    "                    post_cbhg_layers_units[i],\n",
    "                    bidirectional=True,\n",
    "                    batch_first=True,\n",
    "                )\n",
    "            )\n",
    "            if post_cbhg_use_batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(post_cbhg_layers_units[i] * 2))\n",
    "\n",
    "        self.post_cbhg_layers = nn.ModuleList(layers)\n",
    "        self.projections = nn.Linear(post_cbhg_layers_units[-1] * 2, targ_vocab_size)\n",
    "        self.post_cbhg_layers_units = post_cbhg_layers_units\n",
    "        self.post_cbhg_use_batch_norm = post_cbhg_use_batch_norm\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,\n",
    "        lengths: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "        \"\"\"Compute forward propagation\"\"\"\n",
    "\n",
    "        # src = [batch_size, src len]\n",
    "        # lengths = [batch_size]\n",
    "        # target = [batch_size, trg len]\n",
    "\n",
    "        embedding_out = self.embedding(src)\n",
    "        # embedding_out; [batch_size, src_len, embedding_dim]\n",
    "\n",
    "        cbhg_input = self.prenet(embedding_out)\n",
    "\n",
    "        # cbhg_input = [batch_size, src_len, prenet_sizes[-1]]\n",
    "\n",
    "        outputs = self.cbhg(cbhg_input, lengths)\n",
    "\n",
    "        hn = torch.zeros((2, 2, 2))\n",
    "        cn = torch.zeros((2, 2, 2))\n",
    "\n",
    "        for i, layer in enumerate(self.post_cbhg_layers):\n",
    "            if isinstance(layer, nn.BatchNorm1d):\n",
    "                outputs = layer(outputs.permute(0, 2, 1))\n",
    "                outputs = outputs.permute(0, 2, 1)\n",
    "                continue\n",
    "            if i > 0:\n",
    "                outputs, (hn, cn) = layer(outputs, (hn, cn))\n",
    "            else:\n",
    "                outputs, (hn, cn) = layer(outputs)\n",
    "\n",
    "\n",
    "        predictions = self.projections(outputs)\n",
    "\n",
    "        return predictions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CBHGModel(len(sentence_encoder.classes_), np.unique(y_train).shape[0]).to(device)\n",
    "model = torch.load('model_cbhg.ckpt')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15560719\n"
     ]
    }
   ],
   "source": [
    "#print #number of trainable parameters only\n",
    "print(\n",
    "    sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_eval(x_np, y_np):\n",
    "    X_tensor = torch.tensor(x_np, dtype=torch.int32)\n",
    "    y_tensor = torch.tensor(y_np, dtype=torch.int32)\n",
    "    model.eval()\n",
    "    predictions = torch.zeros_like(y_tensor)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X_tensor), batch_size):\n",
    "            inputs = X_tensor[i:i+batch_size].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions[i:i+batch_size] = torch.max(outputs.data, 2)\n",
    "            del inputs, outputs\n",
    "\n",
    "    return predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DER(X, y):\n",
    "    predictions = batch_eval(X, y)\n",
    "    ignore = {'!', '«', ']', '[', '}', ':', '\"', '-', '»', '؛', ')', '،', '؟', '(', '{', '/', ' ', PAD, SOS, EOS}\n",
    "    cnt = 0\n",
    "    for itm in ignore:\n",
    "        cnt += np.sum(X == sentence_encoder.transform(np.array([ord(itm)]))[0])\n",
    "    accuracy = (np.sum(predictions == y) - cnt) / (predictions.shape[0] * predictions.shape[1] - cnt)\n",
    "    return 1 - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [625/625], Epoch [1/20], Loss: 0.0073, Accuracy: 0.9974\n",
      "DER: 0.02925\n",
      "Step [625/625], Epoch [2/20], Loss: 0.0063, Accuracy: 0.9977\n",
      "DER: 0.02992\n",
      "Step [625/625], Epoch [3/20], Loss: 0.0066, Accuracy: 0.9977\n",
      "DER: 0.02958\n",
      "Step [41/625], Epoch [4/20], Loss: 0.0053, Accuracy: 0.9982\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39munique(y_train)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\John\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.int64).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.int64).to(device)\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    accuracy = 0\n",
    "    loss_cum_sum = 0\n",
    "    len_ = 0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs.view(-1, np.unique(y_train).shape[0]), y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 2)\n",
    "        accuracy += (predicted == y).sum().item()\n",
    "        loss_cum_sum += loss.item()\n",
    "        len_ += y.size(0) * y.size(1)\n",
    "        if (i + 1) % 1 == 0:\n",
    "            print('Step [{}/{}], Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}'.format(i + 1, len(train_loader), epoch + 1, num_epochs, loss_cum_sum / (i + 1), accuracy / len_), end='\\r')\n",
    "    print()\n",
    "    del X_train_tensor, y_train_tensor, train_dataset, train_loader\n",
    "    print('DER: {:.5f}'.format(compute_DER(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_cbhg.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DER: 0.02850\n"
     ]
    }
   ],
   "source": [
    "print('DER: {:.5f}'.format(compute_DER(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritize_string(sentence_test_str, model, sentence_encoder, max_len):\n",
    "    sentence = SOS + sentence_test_str + EOS\n",
    "    sentence_no_diacritics, labels = extract_data_single(sentence)\n",
    "    sentence_no_diac_clamped, labels_clamped = clamp_sentence(sentence_no_diacritics, labels, max_len)\n",
    "    sentence, labels_encoded = encode_sentences(sentence_no_diac_clamped, labels_clamped)\n",
    "    sentence = sentence_encoder.transform(sentence.reshape(-1)).reshape(1, -1)\n",
    "    \n",
    "    sentence = torch.tensor(sentence, dtype=torch.int32).to(device)\n",
    "    outputs = model(sentence)\n",
    "    _, pred = torch.max(outputs.data, 2)\n",
    "    pred = pred.cpu().numpy().reshape(-1)\n",
    "\n",
    "    sentence = ''\n",
    "    for i in range(len(sentence_no_diacritics)):\n",
    "        sentence += sentence_no_diacritics[i]\n",
    "        sentence += id2diacritic[pred[i]]\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "كَانَ مَعَهُ أَلْفٌ فَقَالَ هِيَ مُضَارَبَةٌ لِفُلَانٍ بِالنِّصْفِ وَقَدْ رَبِحَ أَلْفًا فَقَالَ فُلَانٌ هِيَ بِضَاعَةٌ فَالْقَوْلُ قَوْلُ رَبِّ الْمَالِ\n",
      "كَانَ مَعَهُ أَلْفٌ فَقَالَ هِيَ مُضَارَبَةٌ لِفُلَانٍ بِالنِّصْفِ وَقَدْ رَبِحَ أَلْفًا فَقَالَ فُلَانٌ هِيَ بِضَاعَةٌ فَالْقَوْلُ قَوْلُ رَبِّ الْمَالِ\n"
     ]
    }
   ],
   "source": [
    "sentence_test_str = 'كَانَ مَعَهُ أَلْفٌ فَقَالَ هِيَ مُضَارَبَةٌ لِفُلَانٍ بِالنِّصْفِ وَقَدْ رَبِحَ أَلْفًا فَقَالَ فُلَانٌ هِيَ بِضَاعَةٌ فَالْقَوْلُ قَوْلُ رَبِّ الْمَالِ'\n",
    "print(sentence_test_str)\n",
    "print(diacritize_string(sentence_test_str, model, sentence_encoder, max_len)[1:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
